{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# How to run code?\n",
        "Run cells in chronological order.\n",
        "\n",
        "# Data Loading Scheme\n",
        "The AudioDataset class sorts the mfcc and transcripts after loading from the directory. For each mfcc, cepstral normalization is done by subtracting the mean and dividing by the standard deviation. For each transcript, [SOS] [EOS] are removed and converted into integers.\n",
        "\n",
        "# Architectures tried\n",
        "1. Encoder: 1 Conv1d + 1 pBLSTM \\\n",
        "   Decoder: \\\n",
        "            torch.nn.Dropout(0.2), \\\n",
        "            torch.nn.Linear(embed_size, 1024), \\\n",
        "            torch.nn.GELU(),\\\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(1024), PermuteBlock(),\\\n",
        "            torch.nn.Dropout(0.2),\\\n",
        "            torch.nn.Linear(1024, 1024),\\\n",
        "            torch.nn.GELU(),\\\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(1024), PermuteBlock(),\\\n",
        "            torch.nn.Dropout(0.2),\\\n",
        "            torch.nn.Linear(1024, 1024),\\\n",
        "            torch.nn.GELU(),\\\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(1024), PermuteBlock(),\\\n",
        "            torch.nn.Dropout(0.2),\\\n",
        "            torch.nn.Linear(1024, output_size),\n",
        "\n",
        "   Beam Width: 2 \\\n",
        "   LR: 2e-3 \\\n",
        "   Epochs: 50 \\\n",
        "   Batch Size: 64 \\\n",
        "   Transforms: torchaudio.transforms.FrequencyMasking(freq_mask_param=10), torchaudio.transforms.TimeMasking(time_mask_param=80), \\\n",
        "   Scheduler: torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.75, patience=1, min_lr=1e-4)\n",
        "\n",
        "2. Encoder: 2 Conv1d + 2 pBLSTM + LockedDropout\\\n",
        "   Decoder: \\\n",
        "            torch.nn.Linear(embed_size, 2000),\\\n",
        "            torch.nn.GELU(),\\\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(2000), PermuteBlock(),\\\n",
        "            torch.nn.Dropout(0.2),\\\n",
        "            torch.nn.Linear(2000, 1000),\\\n",
        "            torch.nn.GELU(),\\\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(1000), PermuteBlock(),\\\n",
        "            torch.nn.Dropout(0.2),\\\n",
        "            torch.nn.Linear(1000, output_size),\n",
        "\n",
        "   Beam Width: 5 \\\n",
        "   LR: 2e-3 \\\n",
        "   Epochs: 50 \\\n",
        "   Batch Size: 128 \\\n",
        "   Transforms: torchaudio.transforms.FrequencyMasking(freq_mask_param=10), torchaudio.transforms.TimeMasking(time_mask_param=80), \\\n",
        "   Scheduler: torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.75, patience=1, min_lr=1e-4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR4qfYrVoO4v"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mA9qZoIDcx-h",
        "outputId": "3edb02e3-0729-4302-efb8-5af87c28c33f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 GB\u001b[0m \u001b[31m575.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/24.3 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "%pip install torch==1.13.1+cu117 torchvision==0.14.1+cu117 torchtext==0.14.1 torchaudio==0.13.1 torchdata==0.5.1 --extra-index-url https://download.pytorch.org/whl/cu117 -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONgAWhqdoYy-"
      },
      "source": [
        "\n",
        "This may take a while"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS7a7xeEoaV9",
        "outputId": "a1995f01-14c3-4cfc-e2f6-cf929f790daa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.5/263.5 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1102, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 1102 (delta 16), reused 32 (delta 14), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1102/1102), 782.27 KiB | 2.92 MiB/s, done.\n",
            "Resolving deltas: 100% (529/529), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Counting objects: 100% (26/26), done.        \n",
            "remote: Compressing objects: 100% (9/9), done.        \n",
            "Receiving objects: 100% (82/82), 13.34 KiB | 253.00 KiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "remote: Total 82 (delta 19), reused 17 (delta 17), pack-reused 56        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 14165, done.        \n",
            "remote: Counting objects: 100% (478/478), done.        \n",
            "remote: Compressing objects: 100% (331/331), done.        \n",
            "remote: Total 14165 (delta 163), reused 409 (delta 133), pack-reused 13687        \n",
            "Receiving objects: 100% (14165/14165), 5.91 MiB | 11.02 MiB/s, done.\n",
            "Resolving deltas: 100% (8043/8043), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content/ctcdecode\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb --quiet\n",
        "!pip install python-Levenshtein -q\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget -q\n",
        "%cd ctcdecode\n",
        "!pip install . -q\n",
        "%cd ..\n",
        "\n",
        "!pip install torchsummaryX -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ti_wUnn_Shxp",
        "outputId": "a6437c07-ec5d-44a1-e0c1-bb0c9f0a7ec0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummaryx==1.3.0 in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchsummaryx==1.3.0) (1.13.1+cu117)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchsummaryx==1.3.0) (1.23.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from torchsummaryx==1.3.0) (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryx==1.3.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->torchsummaryx==1.3.0) (2023.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchsummaryx==1.3.0) (4.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->torchsummaryx==1.3.0) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "If torchsummaryX doesn't work, please run this cell. Alternatively, please refer to Piazza post @209 for more assistance:\n",
        "'''\n",
        "\n",
        "!pip install torchsummaryx==1.3.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVONJxCobPc"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78ZTCIXoof2f",
        "outputId": "714643b4-22b5-4d71-a8f4-f561b031f330"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummaryX import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torchaudio.transforms as tat\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import datetime\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3-yJ8tok34"
      },
      "source": [
        "# Kaggle Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdUelfGhom1m",
        "outputId": "1048177a-b923-4233-b611-b5964407af65"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/59.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for kaggle (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8 -q\n",
        "!mkdir /root/.kaggle\n",
        "\n",
        "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "    f.write('{\"username\":\"\",\"key\":\"\"}')\n",
        "\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSjBwfXeoq4B",
        "outputId": "6e9d9d80-3144-434a-a920-674092479238"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading hw3p2asr-s24.zip to /content\n",
            "100% 3.72G/3.74G [00:25<00:00, 192MB/s]\n",
            "100% 3.74G/3.74G [00:26<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c hw3p2asr-s24"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ruxWP60LCQA",
        "outputId": "9b2b0795-5037-4f25-b047-6631963a038d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11-785-s24-hw3p2  ctcdecode  hw3p2asr-s24.zip  sample_data\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This will take a couple minutes, but you should see at least the following:\n",
        "11-785-s24-hw3p2  ctcdecode  hw3p2asr-s24.zip  sample_data\n",
        "'''\n",
        "!unzip -q hw3p2asr-s24.zip\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ORNHnSFroP0"
      },
      "source": [
        "# Dataset and Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0v7wHRWrqH6"
      },
      "outputs": [],
      "source": [
        "# ARPABET PHONEME MAPPING\n",
        "# DO NOT CHANGE\n",
        "\n",
        "CMUdict_ARPAbet = {\n",
        "    \"\" : \" \",\n",
        "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\" : \"f\", \"M\" : \"m\", \"AE\": \"@\",\n",
        "    \"R\"    : \"r\", \"UW\": \"u\", \"N\" : \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
        "    \"V\"    : \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
        "    \"HH\"   : \"h\", \"Z\" : \"z\", \"K\" : \"k\", \"CH\": \"C\", \"W\" : \"w\",\n",
        "    \"EY\"   : \"e\", \"ZH\": \"Z\", \"T\" : \"t\", \"EH\": \"E\", \"Y\" : \"y\",\n",
        "    \"AH\"   : \"A\", \"B\" : \"b\", \"P\" : \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
        "    \"AO\"   : \"c\", \"G\" : \"g\", \"L\" : \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
        "    \"SH\"   : \"S\", \"D\" : \"d\", \"AY\": \"Y\", \"S\" : \"s\", \"IH\": \"I\",\n",
        "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
        "}\n",
        "\n",
        "CMUdict = list(CMUdict_ARPAbet.keys())\n",
        "ARPAbet = list(CMUdict_ARPAbet.values())\n",
        "\n",
        "\n",
        "PHONEMES = CMUdict[:-2]\n",
        "LABELS = ARPAbet[:-2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmNBKf4JrLV"
      },
      "source": [
        "### Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afd0_vlbJmr_"
      },
      "outputs": [],
      "source": [
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "     \n",
        "    def __init__(self, root='/content/11-785-s24-hw3p2/', phonemes = PHONEMES, partition= \"train-clean-100\"):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "\n",
        "        self.mfcc_dir = root + partition + '/mfcc/'  \n",
        "        self.transcript_dir = root + partition + '/transcript/'  \n",
        "\n",
        "        self.mfccs = []  \n",
        "        self.transcripts = []  \n",
        "\n",
        "        self.PHONEMES = PHONEMES\n",
        "\n",
        "        mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "        transcript_names    = sorted(os.listdir(self.transcript_dir))\n",
        "\n",
        "        for i in range(len(mfcc_names)):\n",
        "            mfcc        = np.load(self.mfcc_dir + mfcc_names[i])\n",
        "            mean        = np.mean(mfcc, axis=0)\n",
        "            std         = np.std(mfcc, axis=0)\n",
        "            mfcc        = (mfcc - mean)/(std + 1e-5)\n",
        "\n",
        "            transcript  = np.load(self.transcript_dir + transcript_names[i])\n",
        "            transcript  = transcript[1:-1]\n",
        "            transcript  = [self.PHONEMES.index(p) for p in transcript]\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "            self.transcripts.append(transcript)\n",
        "\n",
        "         \n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "         \n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "\n",
        "         \n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        # self.mfccs          = np.vstack(self.mfccs)\n",
        "        # self.transcripts    = np.hstack(self.transcripts)\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "\n",
        "        # raise NotImplemented\n",
        "\n",
        "        mfcc = torch.FloatTensor(self.mfccs[ind]) # TODO\n",
        "        transcript = torch.FloatTensor(self.transcripts[ind]) # TODO\n",
        "\n",
        "        return mfcc, transcript\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lenghts of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "        # import pdb; pdb.set_trace()\n",
        "        batch_mfcc, batch_transcript, lengths_mfcc, lengths_transcript = [], [], [], []\n",
        "        for mfcc, transcript in batch:\n",
        "          # batch of input mfcc coefficients\n",
        "          batch_mfcc.append(mfcc) # TODO\n",
        "          lengths_mfcc.append(len(mfcc))\n",
        "          # batch of output phonemes\n",
        "          batch_transcript.append(transcript) # TODO\n",
        "          lengths_transcript.append(len(transcript))\n",
        "\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "\n",
        "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True) # TODO\n",
        "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first=True) # TODO\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqDrxeHfJw4g"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrLS1wfVJppA"
      },
      "outputs": [],
      "source": [
        "# Test Dataloader\n",
        "class AudioDatasetTest(torch.utils.data.Dataset):\n",
        "\n",
        "    # For this homework, we give you full flexibility to design your data set class.\n",
        "    # Hint: The data from HW1 is very similar to this HW\n",
        "\n",
        "     \n",
        "    def __init__(self, root='/content/11-785-s24-hw3p2/', phonemes = PHONEMES, partition= \"train-clean-100\"):\n",
        "        '''\n",
        "        Initializes the dataset.\n",
        "\n",
        "        INPUTS: What inputs do you need here?\n",
        "        '''\n",
        "\n",
        "        # Load the directory and all files in them\n",
        "\n",
        "        self.mfcc_dir = root + partition + '/mfcc/'  \n",
        "        # self.transcript_dir = root + partition + '/transcript/'  \n",
        "\n",
        "        self.mfccs = []  \n",
        "        # self.transcripts = []  \n",
        "\n",
        "        self.PHONEMES = PHONEMES\n",
        "\n",
        "        mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "        # transcript_names    = sorted(os.listdir(self.transcript_dir))\n",
        "\n",
        "        for i in range(len(mfcc_names)):\n",
        "            mfcc        = np.load(self.mfcc_dir + mfcc_names[i])\n",
        "            mean        = np.mean(mfcc, axis=0)\n",
        "            std         = np.std(mfcc, axis=0)\n",
        "            mfcc        = (mfcc - mean)/(std + 1e-5)\n",
        "\n",
        "            # transcript  = np.load(self.transcript_dir + transcript_names[i])\n",
        "            # transcript  = transcript[1:-1]\n",
        "            # transcript  = [self.PHONEMES.index(p) for p in transcript]\n",
        "\n",
        "            self.mfccs.append(mfcc)\n",
        "            # self.transcripts.append(transcript)\n",
        "\n",
        "         \n",
        "        # WHAT SHOULD THE LENGTH OF THE DATASET BE?\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "         \n",
        "        # HOW CAN WE REPRESENT PHONEMES? CAN WE CREATE A MAPPING FOR THEM?\n",
        "        # HINT: TENSORS CANNOT STORE NON-NUMERICAL VALUES OR STRINGS\n",
        "\n",
        "         \n",
        "        # CREATE AN ARRAY OF ALL FEATUERS AND LABELS\n",
        "        # WHAT NORMALIZATION TECHNIQUE DID YOU USE IN HW1? CAN WE USE IT HERE?\n",
        "        # self.mfccs          = np.vstack(self.mfccs)\n",
        "        # self.transcripts    = np.hstack(self.transcripts)\n",
        "        '''\n",
        "        You may decide to do this in __getitem__ if you wish.\n",
        "        However, doing this here will make the __init__ function take the load of\n",
        "        loading the data, and shift it away from training.\n",
        "        '''\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        '''\n",
        "        TODO: What do we return here?\n",
        "        '''\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        '''\n",
        "        TODO: RETURN THE MFCC COEFFICIENTS AND ITS CORRESPONDING LABELS\n",
        "\n",
        "        If you didn't do the loading and processing of the data in __init__,\n",
        "        do that here.\n",
        "\n",
        "        Once done, return a tuple of features and labels.\n",
        "        '''\n",
        "\n",
        "        # raise NotImplemented\n",
        "\n",
        "        mfcc = torch.FloatTensor(self.mfccs[ind]) # TODO\n",
        "        # transcript = torch.FloatTensor(self.transcripts[ind]) # TODO\n",
        "\n",
        "        return mfcc\n",
        "\n",
        "\n",
        "    def collate_fn(self,batch):\n",
        "        '''\n",
        "        TODO:\n",
        "        1.  Extract the features and labels from 'batch'\n",
        "        2.  We will additionally need to pad both features and labels,\n",
        "            look at pytorch's docs for pad_sequence\n",
        "        3.  This is a good place to perform transforms, if you so wish.\n",
        "            Performing them on batches will speed the process up a bit.\n",
        "        4.  Return batch of features, labels, lenghts of features,\n",
        "            and lengths of labels.\n",
        "        '''\n",
        "        # import pdb; pdb.set_trace()\n",
        "        batch_mfcc, lengths_mfcc = [], []\n",
        "        for mfcc in batch:\n",
        "          # batch of input mfcc coefficients\n",
        "          batch_mfcc.append(mfcc) # TODO\n",
        "          lengths_mfcc.append(len(mfcc))\n",
        "          # batch of output phonemes\n",
        "          # batch_transcript.append(transcript) # TODO\n",
        "          # lengths_transcript.append(len(transcript))\n",
        "\n",
        "\n",
        "        # HINT: CHECK OUT -> pad_sequence (imported above)\n",
        "        # Also be sure to check the input format (batch_first)\n",
        "\n",
        "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True) # TODO\n",
        "        # batch_transcript_pad = pad_sequence(batch_transcript, batch_first=True) # TODO\n",
        "\n",
        "        # You may apply some transformation, Time and Frequency masking, here in the collate function;\n",
        "        # Food for thought -> Why are we applying the transformation here and not in the __getitem__?\n",
        "        #                  -> Would we apply transformation on the validation set as well?\n",
        "        #                  -> Is the order of axes / dimensions as expected for the transform functions?\n",
        "\n",
        "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
        "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt-veYcdL6Fe"
      },
      "source": [
        "### Config - Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MN82c3KpLup8"
      },
      "outputs": [],
      "source": [
        "root = '/content/11-785-s24-hw3p2/'\n",
        "\n",
        "# Feel free to add more items here\n",
        "config = {\n",
        "    \"beam_width\" : 5,\n",
        "    \"lr\"         : 2e-3,\n",
        "    \"epochs\"     : 50,\n",
        "    \"batch_size\" : 128  # Increase if your device can handle it\n",
        "}\n",
        "\n",
        "# You may pass this as a parameter to the dataset class above\n",
        "# This will help modularize your implementation\n",
        "transforms = [] # set of tranformations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmuPk9J6L8dz"
      },
      "source": [
        "### Data loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_kG0gU2x4hH",
        "outputId": "b105b04e-6495-4bc5-e213-f0ca3e3f21a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get me RAMMM!!!!\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOu_zUEJ44LM"
      },
      "outputs": [],
      "source": [
        "# Create objects for the dataset class\n",
        "train_data = AudioDataset(root='/content/11-785-s24-hw3p2/', phonemes = PHONEMES, partition= \"train-clean-100\")  \n",
        "val_data = AudioDataset(root='/content/11-785-s24-hw3p2/', phonemes = PHONEMES, partition= \"dev-clean\", ) # TODO : You can either use the same class with some modifications or make a new one :)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mte3YJeu838s"
      },
      "outputs": [],
      "source": [
        "test_data = AudioDatasetTest(root='/content/11-785-s24-hw3p2/', phonemes = PHONEMES, partition= \"test-clean\", )  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C623WtFo8-u9"
      },
      "outputs": [],
      "source": [
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data,\n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'],\n",
        "    collate_fn  = test_data.collate_fn,\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mzoYfTKu14s",
        "outputId": "2c5832d1-ddb3-4227-8062-24d226b9fae2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size:  128\n",
            "Train dataset samples = 28539, batches = 223\n",
            "Val dataset samples = 2703, batches = 22\n",
            "Test dataset samples = 2620, batches = 21\n"
          ]
        }
      ],
      "source": [
        "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data,\n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'],\n",
        "    collate_fn  = train_data.collate_fn,\n",
        "    pin_memory  = True,\n",
        "    shuffle     = True\n",
        ")\n",
        " \n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data,\n",
        "    num_workers = 4,\n",
        "    batch_size  = config['batch_size'],\n",
        "    collate_fn  = val_data.collate_fn,\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ") \n",
        "\n",
        "\n",
        "print(\"Batch size: \", config['batch_size'])\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXMtwyviKaxK",
        "outputId": "02185591-c3d8-488d-c232-d369cbcc5081"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 1673, 27]) torch.Size([128, 220]) torch.Size([128]) torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "# sanity check\n",
        "for data in train_loader:\n",
        "    x, y, lx, ly = data\n",
        "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSexxhdfMUzx"
      },
      "source": [
        "# NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-qb7wnAzCZl"
      },
      "source": [
        "## ASR Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB6eh3gnMUzy"
      },
      "source": [
        "### Pyramid Bi-LSTM (pBLSTM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qd4BEX_yMUzz"
      },
      "outputs": [],
      "source": [
        "# Utils for network\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "class PermuteBlock(torch.nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.transpose(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmdyXI6KMUzz"
      },
      "outputs": [],
      "source": [
        "class pBLSTM(torch.nn.Module):\n",
        "\n",
        "    '''\n",
        "    Pyramidal BiLSTM\n",
        "    Read the write up/paper and understand the concepts and then write your implementation here.\n",
        "\n",
        "    At each step,\n",
        "    1. Pad your input if it is packed (Unpack it)\n",
        "    2. Reduce the input length dimension by concatenating feature dimension\n",
        "        (Tip: Write down the shapes and understand)\n",
        "        (i) How should  you deal with odd/even length input?\n",
        "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
        "    3. Pack your input\n",
        "    4. Pass it into LSTM layer\n",
        "\n",
        "    To make our implementation modular, we pass 1 layer at a time.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(pBLSTM, self).__init__()\n",
        "\n",
        "        self.blstm = nn.LSTM(2*input_size, hidden_size, num_layers=1, bidirectional=True, batch_first=True, dropout=0.2) # TODO: Initialize a single layer bidirectional LSTM with the given input_size and hidden_size\n",
        "\n",
        "    def forward(self, x_packed): # x_packed is a PackedSequence\n",
        "\n",
        "        # TODO: Pad Packed Sequence\n",
        "        x, x_lens = pad_packed_sequence(x_packed, batch_first=True)\n",
        "        # Call self.trunc_reshape() which downsamples the time steps of x and increases the feature dimensions as mentioned above\n",
        "        # self.trunc_reshape will return 2 outputs. What are they? Think about what quantites are changing.\n",
        "        x, x_lens = self.trunc_reshape(x, x_lens)\n",
        "        # TODO: Pack Padded Sequence. What output(s) would you get?\n",
        "        x = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "        # TODO: Pass the sequence through bLSTM\n",
        "        x, _ = self.blstm(x)\n",
        "        # What do you return?\n",
        "\n",
        "        return x\n",
        "\n",
        "    def trunc_reshape(self, x, x_lens):\n",
        "        # TODO: If you have odd number of timesteps, how can you handle it? (Hint: You can exclude them)\n",
        "        if x.shape[1]%2 != 0:\n",
        "          x = x[:,:-1,:]\n",
        "        # TODO: Reshape x. When reshaping x, you have to reduce number of timesteps by a downsampling factor while increasing number of features by the same factor\n",
        "        x = x.reshape(x.shape[0], x.shape[1]//2, x.shape[2]*2)\n",
        "        # TODO: Reduce lengths by the same downsampling factor\n",
        "        x_lens = x_lens//2\n",
        "        return x, x_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3ZQ75OcMUz0"
      },
      "source": [
        "### Encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4py3YZ896OvR"
      },
      "outputs": [],
      "source": [
        "class LockedDropout(nn.Module):\n",
        "    def __init__(self, p=0.4):\n",
        "        # https://pytorchnlp.readthedocs.io/en/latest/_modules/torchnlp/nn/lock_dropout.html\n",
        "        super().__init__()\n",
        "        self.p = p\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.training or not self.p:\n",
        "            return x\n",
        "        x, x_lens = pad_packed_sequence(x, batch_first=True)\n",
        "        mask = x.new_empty(x.size(0), 1, x.size(2), requires_grad=False).bernoulli_(1 - self.p).div_(1 - self.p)\n",
        "        x = x * mask.expand_as(x)\n",
        "        x = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEzw5_xmMUz0"
      },
      "outputs": [],
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "    '''\n",
        "    The Encoder takes utterances as inputs and returns latent feature representations\n",
        "    '''\n",
        "    def __init__(self, input_size, encoder_hidden_size):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "\n",
        "        self.embedding = torch.nn.Sequential(\n",
        "            PermuteBlock(),\n",
        "            torch.nn.Conv1d(in_channels=input_size, out_channels=128, kernel_size=3, padding=1, stride=1),\n",
        "            torch.nn.BatchNorm1d(128),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1, stride=1),\n",
        "            torch.nn.BatchNorm1d(256),\n",
        "            PermuteBlock(),\n",
        "        )\n",
        "        #TODO : You can use CNNs as Embedding layer to extract features. Keep in mind the Input dimensions and expected dimension of Pytorch CNN.\n",
        "\n",
        "        self.pBLSTMs = torch.nn.Sequential( # How many pBLSTMs are required?\n",
        "            # TODO: Fill this up with pBLSTMs - What should the input_size be?\n",
        "            # Hint: You are downsampling timesteps by a factor of 2, upsampling features by a factor of 2 and the LSTM is bidirectional)\n",
        "            # Optional: Dropout/Locked Dropout after each pBLSTM (Not needed for early submission)\n",
        "            # https://github.com/salesforce/awd-lstm-lm/blob/dfd3cb0235d2caf2847a4d53e1cbd495b781b5d2/locked_dropout.py#L5\n",
        "            # ...\n",
        "            # ...\n",
        "            pBLSTM(input_size=256, hidden_size=encoder_hidden_size),\n",
        "            LockedDropout(),\n",
        "            pBLSTM(input_size=2*encoder_hidden_size, hidden_size=encoder_hidden_size),\n",
        "            LockedDropout(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, x_lens):\n",
        "        # Where are x and x_lens coming from? The dataloader\n",
        "        #TODO: Call the embedding layer\n",
        "        x = self.embedding(x)\n",
        "        # TODO: Pack Padded Sequence\n",
        "        x = pack_padded_sequence(x, x_lens, batch_first=True, enforce_sorted=False)\n",
        "        # TODO: Pass Sequence through the pyramidal Bi-LSTM layer\n",
        "        x = self.pBLSTMs(x)\n",
        "        # TODO: Pad Packed Sequence\n",
        "        encoder_outputs, encoder_lens = pad_packed_sequence(x, batch_first=True)\n",
        "\n",
        "        # Remember the number of output(s) each function returns\n",
        "\n",
        "        return encoder_outputs, encoder_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg82HXa3MUz1"
      },
      "source": [
        "### Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQIRxdNTMUz1"
      },
      "outputs": [],
      "source": [
        "class Decoder(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, embed_size, output_size= 41):\n",
        "        super().__init__()\n",
        "\n",
        "        self.mlp = torch.nn.Sequential(\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(embed_size), PermuteBlock(),\n",
        "            #TODO define your MLP arch. Refer HW1P2\n",
        "            #Use Permute Block before and after BatchNorm1d() to match the size\n",
        "            torch.nn.Linear(embed_size, 2000),\n",
        "            torch.nn.GELU(),\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(2000), PermuteBlock(),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(2000, 1000),\n",
        "            torch.nn.GELU(),\n",
        "            PermuteBlock(), torch.nn.BatchNorm1d(1000), PermuteBlock(),\n",
        "            torch.nn.Dropout(0.2),\n",
        "            torch.nn.Linear(1000, output_size),\n",
        "        )\n",
        "\n",
        "        self.softmax = torch.nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, encoder_out):\n",
        "        #TODO  call your MLP\n",
        "        x = self.mlp(encoder_out)\n",
        "        #TODO Think what should be the final output of the decoder for the classification\n",
        "        out = self.softmax(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1vw1Yiy-HsU"
      },
      "outputs": [],
      "source": [
        "import torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmHf6pFiMUz1"
      },
      "outputs": [],
      "source": [
        "class ASRModel(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, embed_size= 192, output_size= len(PHONEMES)):\n",
        "        super().__init__()\n",
        "\n",
        "        self.augmentations  = torch.nn.Sequential(\n",
        "            #TODO Add Time Masking/ Frequency Masking\n",
        "            #Hint: See how to use PermuteBlock() function defined above\n",
        "            PermuteBlock(),\n",
        "            torchaudio.transforms.FrequencyMasking(freq_mask_param=10),\n",
        "            torchaudio.transforms.TimeMasking(time_mask_param=80),\n",
        "            PermuteBlock(),\n",
        "        )\n",
        "        self.encoder        = Encoder(input_size, embed_size)# TODO: Initialize Encoder\n",
        "        self.decoder        = Decoder(2*embed_size, output_size)# TODO: Initialize Decoder\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x, lengths_x):\n",
        "\n",
        "        if self.training:\n",
        "            x = self.augmentations(x)\n",
        "\n",
        "        encoder_out, encoder_lens   = self.encoder(x, lengths_x)\n",
        "        decoder_out                 = self.decoder(encoder_out)\n",
        "\n",
        "        return decoder_out, encoder_lens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EV7DMPDoMUz2"
      },
      "source": [
        "## Initialize ASR Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oaaDsnnLMUz2",
        "outputId": "86cd3799-8e6e-4cb5-b84e-fac0a6a1c610"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ASRModel(\n",
            "  (augmentations): Sequential(\n",
            "    (0): PermuteBlock()\n",
            "    (1): FrequencyMasking()\n",
            "    (2): TimeMasking()\n",
            "    (3): PermuteBlock()\n",
            "  )\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): Conv1d(27, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (3): GELU(approximate='none')\n",
            "      (4): Conv1d(128, 256, kernel_size=(3,), stride=(1,), padding=(1,))\n",
            "      (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (6): PermuteBlock()\n",
            "    )\n",
            "    (pBLSTMs): Sequential(\n",
            "      (0): pBLSTM(\n",
            "        (blstm): LSTM(512, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "      )\n",
            "      (1): LockedDropout()\n",
            "      (2): pBLSTM(\n",
            "        (blstm): LSTM(2048, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
            "      )\n",
            "      (3): LockedDropout()\n",
            "    )\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (mlp): Sequential(\n",
            "      (0): PermuteBlock()\n",
            "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PermuteBlock()\n",
            "      (3): Linear(in_features=1024, out_features=2000, bias=True)\n",
            "      (4): GELU(approximate='none')\n",
            "      (5): PermuteBlock()\n",
            "      (6): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (7): PermuteBlock()\n",
            "      (8): Dropout(p=0.2, inplace=False)\n",
            "      (9): Linear(in_features=2000, out_features=1000, bias=True)\n",
            "      (10): GELU(approximate='none')\n",
            "      (11): PermuteBlock()\n",
            "      (12): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (13): PermuteBlock()\n",
            "      (14): Dropout(p=0.2, inplace=False)\n",
            "      (15): Linear(in_features=1000, out_features=41, bias=True)\n",
            "    )\n",
            "    (softmax): LogSoftmax(dim=2)\n",
            "  )\n",
            ")\n",
            "=============================================================================================\n",
            "                                      Kernel Shape      Output Shape  \\\n",
            "Layer                                                                  \n",
            "0_augmentations.PermuteBlock_0                   -   [128, 27, 1673]   \n",
            "1_augmentations.FrequencyMasking_1               -   [128, 27, 1673]   \n",
            "2_augmentations.TimeMasking_2                    -   [128, 27, 1673]   \n",
            "3_augmentations.PermuteBlock_3                   -   [128, 1673, 27]   \n",
            "4_encoder.embedding.PermuteBlock_0               -   [128, 27, 1673]   \n",
            "5_encoder.embedding.Conv1d_1          [27, 128, 3]  [128, 128, 1673]   \n",
            "6_encoder.embedding.BatchNorm1d_2            [128]  [128, 128, 1673]   \n",
            "7_encoder.embedding.GELU_3                       -  [128, 128, 1673]   \n",
            "8_encoder.embedding.Conv1d_4         [128, 256, 3]  [128, 256, 1673]   \n",
            "9_encoder.embedding.BatchNorm1d_5            [256]  [128, 256, 1673]   \n",
            "10_encoder.embedding.PermuteBlock_6              -  [128, 1673, 256]   \n",
            "11_encoder.pBLSTMs.0.LSTM_blstm                  -     [80172, 1024]   \n",
            "12_encoder.pBLSTMs.LockedDropout_1               -     [80172, 1024]   \n",
            "13_encoder.pBLSTMs.2.LSTM_blstm                  -     [40053, 1024]   \n",
            "14_encoder.pBLSTMs.LockedDropout_3               -     [40053, 1024]   \n",
            "15_decoder.mlp.PermuteBlock_0                    -  [128, 1024, 418]   \n",
            "16_decoder.mlp.BatchNorm1d_1                [1024]  [128, 1024, 418]   \n",
            "17_decoder.mlp.PermuteBlock_2                    -  [128, 418, 1024]   \n",
            "18_decoder.mlp.Linear_3               [1024, 2000]  [128, 418, 2000]   \n",
            "19_decoder.mlp.GELU_4                            -  [128, 418, 2000]   \n",
            "20_decoder.mlp.PermuteBlock_5                    -  [128, 2000, 418]   \n",
            "21_decoder.mlp.BatchNorm1d_6                [2000]  [128, 2000, 418]   \n",
            "22_decoder.mlp.PermuteBlock_7                    -  [128, 418, 2000]   \n",
            "23_decoder.mlp.Dropout_8                         -  [128, 418, 2000]   \n",
            "24_decoder.mlp.Linear_9               [2000, 1000]  [128, 418, 1000]   \n",
            "25_decoder.mlp.GELU_10                           -  [128, 418, 1000]   \n",
            "26_decoder.mlp.PermuteBlock_11                   -  [128, 1000, 418]   \n",
            "27_decoder.mlp.BatchNorm1d_12               [1000]  [128, 1000, 418]   \n",
            "28_decoder.mlp.PermuteBlock_13                   -  [128, 418, 1000]   \n",
            "29_decoder.mlp.Dropout_14                        -  [128, 418, 1000]   \n",
            "30_decoder.mlp.Linear_15                [1000, 41]    [128, 418, 41]   \n",
            "31_decoder.LogSoftmax_softmax                    -    [128, 418, 41]   \n",
            "\n",
            "                                         Params    Mult-Adds  \n",
            "Layer                                                         \n",
            "0_augmentations.PermuteBlock_0                -            -  \n",
            "1_augmentations.FrequencyMasking_1            -            -  \n",
            "2_augmentations.TimeMasking_2                 -            -  \n",
            "3_augmentations.PermuteBlock_3                -            -  \n",
            "4_encoder.embedding.PermuteBlock_0            -            -  \n",
            "5_encoder.embedding.Conv1d_1            10.496k   17.345664M  \n",
            "6_encoder.embedding.BatchNorm1d_2         256.0        128.0  \n",
            "7_encoder.embedding.GELU_3                    -            -  \n",
            "8_encoder.embedding.Conv1d_4             98.56k  164.462592M  \n",
            "9_encoder.embedding.BatchNorm1d_5         512.0        256.0  \n",
            "10_encoder.embedding.PermuteBlock_6           -            -  \n",
            "11_encoder.pBLSTMs.0.LSTM_blstm       4.202496M    4.194304M  \n",
            "12_encoder.pBLSTMs.LockedDropout_1            -            -  \n",
            "13_encoder.pBLSTMs.2.LSTM_blstm      10.493952M    10.48576M  \n",
            "14_encoder.pBLSTMs.LockedDropout_3            -            -  \n",
            "15_decoder.mlp.PermuteBlock_0                 -            -  \n",
            "16_decoder.mlp.BatchNorm1d_1             2.048k       1.024k  \n",
            "17_decoder.mlp.PermuteBlock_2                 -            -  \n",
            "18_decoder.mlp.Linear_3                   2.05M       2.048M  \n",
            "19_decoder.mlp.GELU_4                         -            -  \n",
            "20_decoder.mlp.PermuteBlock_5                 -            -  \n",
            "21_decoder.mlp.BatchNorm1d_6               4.0k         2.0k  \n",
            "22_decoder.mlp.PermuteBlock_7                 -            -  \n",
            "23_decoder.mlp.Dropout_8                      -            -  \n",
            "24_decoder.mlp.Linear_9                  2.001M         2.0M  \n",
            "25_decoder.mlp.GELU_10                        -            -  \n",
            "26_decoder.mlp.PermuteBlock_11                -            -  \n",
            "27_decoder.mlp.BatchNorm1d_12              2.0k         1.0k  \n",
            "28_decoder.mlp.PermuteBlock_13                -            -  \n",
            "29_decoder.mlp.Dropout_14                     -            -  \n",
            "30_decoder.mlp.Linear_15                41.041k        41.0k  \n",
            "31_decoder.LogSoftmax_softmax                 -            -  \n",
            "---------------------------------------------------------------------------------------------\n",
            "                           Totals\n",
            "Total params           18.906361M\n",
            "Trainable params       18.906361M\n",
            "Non-trainable params          0.0\n",
            "Mult-Adds             200.581728M\n",
            "=============================================================================================\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "repr_error": "unhashable type: 'list'",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-ef67f79d-7c43-4cc4-9f62-557faf5ee646\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Kernel Shape</th>\n",
              "      <th>Output Shape</th>\n",
              "      <th>Params</th>\n",
              "      <th>Mult-Adds</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Layer</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0_augmentations.PermuteBlock_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 27, 1673]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1_augmentations.FrequencyMasking_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 27, 1673]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2_augmentations.TimeMasking_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 27, 1673]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3_augmentations.PermuteBlock_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 1673, 27]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4_encoder.embedding.PermuteBlock_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 27, 1673]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5_encoder.embedding.Conv1d_1</th>\n",
              "      <td>[27, 128, 3]</td>\n",
              "      <td>[128, 128, 1673]</td>\n",
              "      <td>10496.0</td>\n",
              "      <td>17345664.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6_encoder.embedding.BatchNorm1d_2</th>\n",
              "      <td>[128]</td>\n",
              "      <td>[128, 128, 1673]</td>\n",
              "      <td>256.0</td>\n",
              "      <td>128.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7_encoder.embedding.GELU_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 128, 1673]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8_encoder.embedding.Conv1d_4</th>\n",
              "      <td>[128, 256, 3]</td>\n",
              "      <td>[128, 256, 1673]</td>\n",
              "      <td>98560.0</td>\n",
              "      <td>164462592.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9_encoder.embedding.BatchNorm1d_5</th>\n",
              "      <td>[256]</td>\n",
              "      <td>[128, 256, 1673]</td>\n",
              "      <td>512.0</td>\n",
              "      <td>256.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10_encoder.embedding.PermuteBlock_6</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 1673, 256]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11_encoder.pBLSTMs.0.LSTM_blstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[80172, 1024]</td>\n",
              "      <td>4202496.0</td>\n",
              "      <td>4194304.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12_encoder.pBLSTMs.LockedDropout_1</th>\n",
              "      <td>-</td>\n",
              "      <td>[80172, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13_encoder.pBLSTMs.2.LSTM_blstm</th>\n",
              "      <td>-</td>\n",
              "      <td>[40053, 1024]</td>\n",
              "      <td>10493952.0</td>\n",
              "      <td>10485760.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14_encoder.pBLSTMs.LockedDropout_3</th>\n",
              "      <td>-</td>\n",
              "      <td>[40053, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15_decoder.mlp.PermuteBlock_0</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 1024, 418]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16_decoder.mlp.BatchNorm1d_1</th>\n",
              "      <td>[1024]</td>\n",
              "      <td>[128, 1024, 418]</td>\n",
              "      <td>2048.0</td>\n",
              "      <td>1024.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17_decoder.mlp.PermuteBlock_2</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 1024]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18_decoder.mlp.Linear_3</th>\n",
              "      <td>[1024, 2000]</td>\n",
              "      <td>[128, 418, 2000]</td>\n",
              "      <td>2050000.0</td>\n",
              "      <td>2048000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19_decoder.mlp.GELU_4</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 2000]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20_decoder.mlp.PermuteBlock_5</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 2000, 418]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21_decoder.mlp.BatchNorm1d_6</th>\n",
              "      <td>[2000]</td>\n",
              "      <td>[128, 2000, 418]</td>\n",
              "      <td>4000.0</td>\n",
              "      <td>2000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22_decoder.mlp.PermuteBlock_7</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 2000]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23_decoder.mlp.Dropout_8</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 2000]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24_decoder.mlp.Linear_9</th>\n",
              "      <td>[2000, 1000]</td>\n",
              "      <td>[128, 418, 1000]</td>\n",
              "      <td>2001000.0</td>\n",
              "      <td>2000000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25_decoder.mlp.GELU_10</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 1000]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26_decoder.mlp.PermuteBlock_11</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 1000, 418]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27_decoder.mlp.BatchNorm1d_12</th>\n",
              "      <td>[1000]</td>\n",
              "      <td>[128, 1000, 418]</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28_decoder.mlp.PermuteBlock_13</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 1000]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29_decoder.mlp.Dropout_14</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 1000]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30_decoder.mlp.Linear_15</th>\n",
              "      <td>[1000, 41]</td>\n",
              "      <td>[128, 418, 41]</td>\n",
              "      <td>41041.0</td>\n",
              "      <td>41000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31_decoder.LogSoftmax_softmax</th>\n",
              "      <td>-</td>\n",
              "      <td>[128, 418, 41]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef67f79d-7c43-4cc4-9f62-557faf5ee646')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ef67f79d-7c43-4cc4-9f62-557faf5ee646 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ef67f79d-7c43-4cc4-9f62-557faf5ee646');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7ab968d3-7c89-459b-b507-bf6bc03e15d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ab968d3-7c89-459b-b507-bf6bc03e15d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7ab968d3-7c89-459b-b507-bf6bc03e15d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                      Kernel Shape      Output Shape  \\\n",
              "Layer                                                                  \n",
              "0_augmentations.PermuteBlock_0                   -   [128, 27, 1673]   \n",
              "1_augmentations.FrequencyMasking_1               -   [128, 27, 1673]   \n",
              "2_augmentations.TimeMasking_2                    -   [128, 27, 1673]   \n",
              "3_augmentations.PermuteBlock_3                   -   [128, 1673, 27]   \n",
              "4_encoder.embedding.PermuteBlock_0               -   [128, 27, 1673]   \n",
              "5_encoder.embedding.Conv1d_1          [27, 128, 3]  [128, 128, 1673]   \n",
              "6_encoder.embedding.BatchNorm1d_2            [128]  [128, 128, 1673]   \n",
              "7_encoder.embedding.GELU_3                       -  [128, 128, 1673]   \n",
              "8_encoder.embedding.Conv1d_4         [128, 256, 3]  [128, 256, 1673]   \n",
              "9_encoder.embedding.BatchNorm1d_5            [256]  [128, 256, 1673]   \n",
              "10_encoder.embedding.PermuteBlock_6              -  [128, 1673, 256]   \n",
              "11_encoder.pBLSTMs.0.LSTM_blstm                  -     [80172, 1024]   \n",
              "12_encoder.pBLSTMs.LockedDropout_1               -     [80172, 1024]   \n",
              "13_encoder.pBLSTMs.2.LSTM_blstm                  -     [40053, 1024]   \n",
              "14_encoder.pBLSTMs.LockedDropout_3               -     [40053, 1024]   \n",
              "15_decoder.mlp.PermuteBlock_0                    -  [128, 1024, 418]   \n",
              "16_decoder.mlp.BatchNorm1d_1                [1024]  [128, 1024, 418]   \n",
              "17_decoder.mlp.PermuteBlock_2                    -  [128, 418, 1024]   \n",
              "18_decoder.mlp.Linear_3               [1024, 2000]  [128, 418, 2000]   \n",
              "19_decoder.mlp.GELU_4                            -  [128, 418, 2000]   \n",
              "20_decoder.mlp.PermuteBlock_5                    -  [128, 2000, 418]   \n",
              "21_decoder.mlp.BatchNorm1d_6                [2000]  [128, 2000, 418]   \n",
              "22_decoder.mlp.PermuteBlock_7                    -  [128, 418, 2000]   \n",
              "23_decoder.mlp.Dropout_8                         -  [128, 418, 2000]   \n",
              "24_decoder.mlp.Linear_9               [2000, 1000]  [128, 418, 1000]   \n",
              "25_decoder.mlp.GELU_10                           -  [128, 418, 1000]   \n",
              "26_decoder.mlp.PermuteBlock_11                   -  [128, 1000, 418]   \n",
              "27_decoder.mlp.BatchNorm1d_12               [1000]  [128, 1000, 418]   \n",
              "28_decoder.mlp.PermuteBlock_13                   -  [128, 418, 1000]   \n",
              "29_decoder.mlp.Dropout_14                        -  [128, 418, 1000]   \n",
              "30_decoder.mlp.Linear_15                [1000, 41]    [128, 418, 41]   \n",
              "31_decoder.LogSoftmax_softmax                    -    [128, 418, 41]   \n",
              "\n",
              "                                         Params    Mult-Adds  \n",
              "Layer                                                         \n",
              "0_augmentations.PermuteBlock_0              NaN          NaN  \n",
              "1_augmentations.FrequencyMasking_1          NaN          NaN  \n",
              "2_augmentations.TimeMasking_2               NaN          NaN  \n",
              "3_augmentations.PermuteBlock_3              NaN          NaN  \n",
              "4_encoder.embedding.PermuteBlock_0          NaN          NaN  \n",
              "5_encoder.embedding.Conv1d_1            10496.0   17345664.0  \n",
              "6_encoder.embedding.BatchNorm1d_2         256.0        128.0  \n",
              "7_encoder.embedding.GELU_3                  NaN          NaN  \n",
              "8_encoder.embedding.Conv1d_4            98560.0  164462592.0  \n",
              "9_encoder.embedding.BatchNorm1d_5         512.0        256.0  \n",
              "10_encoder.embedding.PermuteBlock_6         NaN          NaN  \n",
              "11_encoder.pBLSTMs.0.LSTM_blstm       4202496.0    4194304.0  \n",
              "12_encoder.pBLSTMs.LockedDropout_1          NaN          NaN  \n",
              "13_encoder.pBLSTMs.2.LSTM_blstm      10493952.0   10485760.0  \n",
              "14_encoder.pBLSTMs.LockedDropout_3          NaN          NaN  \n",
              "15_decoder.mlp.PermuteBlock_0               NaN          NaN  \n",
              "16_decoder.mlp.BatchNorm1d_1             2048.0       1024.0  \n",
              "17_decoder.mlp.PermuteBlock_2               NaN          NaN  \n",
              "18_decoder.mlp.Linear_3               2050000.0    2048000.0  \n",
              "19_decoder.mlp.GELU_4                       NaN          NaN  \n",
              "20_decoder.mlp.PermuteBlock_5               NaN          NaN  \n",
              "21_decoder.mlp.BatchNorm1d_6             4000.0       2000.0  \n",
              "22_decoder.mlp.PermuteBlock_7               NaN          NaN  \n",
              "23_decoder.mlp.Dropout_8                    NaN          NaN  \n",
              "24_decoder.mlp.Linear_9               2001000.0    2000000.0  \n",
              "25_decoder.mlp.GELU_10                      NaN          NaN  \n",
              "26_decoder.mlp.PermuteBlock_11              NaN          NaN  \n",
              "27_decoder.mlp.BatchNorm1d_12            2000.0       1000.0  \n",
              "28_decoder.mlp.PermuteBlock_13              NaN          NaN  \n",
              "29_decoder.mlp.Dropout_14                   NaN          NaN  \n",
              "30_decoder.mlp.Linear_15                41041.0      41000.0  \n",
              "31_decoder.LogSoftmax_softmax               NaN          NaN  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ASRModel(\n",
        "    input_size  = 27,\n",
        "    embed_size  = 512,  \n",
        "    output_size = len(PHONEMES)\n",
        ").to(device)\n",
        "print(model)\n",
        "summary(model, x.to(device), lx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Config\n",
        "Initialize Loss Criterion, Optimizer, CTC Beam Decoder, Scheduler, Scaler (Mixed-Precision), etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGoozH2nd6KB"
      },
      "outputs": [],
      "source": [
        "#TODO\n",
        "\n",
        "\n",
        "criterion = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False) # Define CTC loss as the criterion. How would the losses be reduced?\n",
        "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
        "# Refer to the handout for hints\n",
        "\n",
        "optimizer =  torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=1e-3) # What goes in here?\n",
        "\n",
        "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
        "# CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
        "decoder = CTCBeamDecoder(LABELS, beam_width=config['beam_width'], log_probs_input=True) \n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.75, patience=1, min_lr=1e-4)  \n",
        "\n",
        "# Mixed Precision, if you need it\n",
        "scaler = torch.cuda.amp.GradScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmc6_4eWL2Xp"
      },
      "source": [
        "# Decode Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHjnCDddL36E"
      },
      "outputs": [],
      "source": [
        "def decode_prediction(output, output_lens, decoder, PHONEME_MAP= LABELS):\n",
        "\n",
        "    # TODO: look at docs for CTC.decoder and find out what is returned here. Check the shape of output and expected shape in decode.\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(output, seq_lens= output_lens) #lengths - list of lengths\n",
        "\n",
        "    pred_strings                    = []\n",
        "\n",
        "    for i in range(output_lens.shape[0]):\n",
        "        #TODO: Create the prediction from the output of decoder.decode. Don't forget to map it using PHONEMES_MAP.\n",
        "        # CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
        "        pred_strings.append(''.join([PHONEME_MAP[n] for n in beam_results[i][0][:out_lens[i][0]]]))\n",
        "    return pred_strings\n",
        "\n",
        "def calculate_levenshtein(output, label, output_lens, label_lens, decoder, PHONEME_MAP= LABELS): # y - sequence of integers\n",
        "\n",
        "    dist            = 0\n",
        "    batch_size      = label.shape[0]\n",
        "\n",
        "    pred_strings    = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        # TODO: Get predicted string and label string for each element in the batch\n",
        "        # CTC Beam Decoder Doc: https://github.com/parlance/ctcdecode\n",
        "        pred_string = pred_strings[i]  \n",
        "        label_string = ''.join([PHONEME_MAP[int(n)] for n in label[i][:label_lens[i]]])  \n",
        "        dist += Levenshtein.distance(pred_string, label_string)\n",
        "\n",
        "    dist /= batch_size # TODO: Uncomment this, but think about why we are doing this\n",
        "    # raise NotImplemented\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qk9iZud1LXT"
      },
      "source": [
        "# Test Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnTLL-5gMBrY",
        "outputId": "1142d07f-9895-4b74-e1e4-5f1cf3a55dcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128, 734, 41])\n",
            "197.859375\n",
            "torch.Size([734, 128, 41]) torch.Size([128, 265])\n",
            "tensor(7.1913, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# test code to check shapes\n",
        "\n",
        "model.eval()\n",
        "for i, data in enumerate(val_loader, 0):\n",
        "    x, y, lx, ly = data\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    h, lh = model(x, lx)\n",
        "    print(h.shape)\n",
        "    print(calculate_levenshtein(h, y, lx, ly, decoder, LABELS))\n",
        "    h = torch.permute(h, (1, 0, 2))\n",
        "    print(h.shape, y.shape)\n",
        "    loss = criterion(h, y, lh, ly)\n",
        "    print(loss)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rd5aNaLVoR_g"
      },
      "source": [
        "# WandB\n",
        "\n",
        "You will need to fetch your api key from wandb.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiDduMaDIARE",
        "outputId": "b79577ac-ed23-4a38-ddab-68dfbc51d0d4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makameswa\u001b[0m (\u001b[33mhickups\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "wandb.login(key=\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "4s52yBOvICPZ",
        "outputId": "336e41ec-f70d-4d77-bf69-52fda459a943"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33makameswa\u001b[0m (\u001b[33mtekkotsu\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.4"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240320_015840-jyqyah20</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/tekkotsu/hw3p2/runs/jyqyah20' target=\"_blank\">high-cutoff</a></strong> to <a href='https://wandb.ai/tekkotsu/hw3p2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/tekkotsu/hw3p2' target=\"_blank\">https://wandb.ai/tekkotsu/hw3p2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/tekkotsu/hw3p2/runs/jyqyah20' target=\"_blank\">https://wandb.ai/tekkotsu/hw3p2/runs/jyqyah20</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "run = wandb.init(\n",
        "    name = \"high-cutoff\", ## Wandb creates random run names if you skip this field\n",
        "    reinit = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    id = \"jyqyah20\", ### Insert specific run id here if you want to resume a previous run\n",
        "    resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"hw3p2\", ### Project should be created in your wandb account\n",
        "    entity=\"tekkotsu\",\n",
        "    config = config ### Wandb Config for your run\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fLLj5KIMMOe"
      },
      "source": [
        "# Train Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ri87MAdhMUz5"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer):\n",
        "\n",
        "    model.train()\n",
        "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
        "\n",
        "        batch_bar.update() # Update tqdm bar\n",
        "\n",
        "        # Another couple things you need for FP16.\n",
        "        scaler.scale(loss).backward() # This is a replacement for loss.backward()\n",
        "        scaler.step(optimizer) # This is a replacement for optimizer.step()\n",
        "        scaler.update() # This is something added just for FP16\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close() # You need this to close the tqdm bar\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "\n",
        "def validate_model(model, val_loader, decoder, phoneme_map= LABELS):\n",
        "\n",
        "    model.eval()\n",
        "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    total_loss = 0\n",
        "    vdist = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        x, y, lx, ly = data\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            h, lh = model(x, lx)\n",
        "            h = torch.permute(h, (1, 0, 2))\n",
        "            loss = criterion(h, y, lh, ly)\n",
        "\n",
        "        total_loss += float(loss)\n",
        "        vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))), dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
        "\n",
        "        batch_bar.update()\n",
        "\n",
        "        del x, y, lx, ly, h, lh, loss\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    batch_bar.close()\n",
        "    total_loss = total_loss/len(val_loader)\n",
        "    val_dist = vdist/len(val_loader)\n",
        "    return total_loss, val_dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpYExu4vT4_g"
      },
      "source": [
        "## Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "husa5_EYMUz6"
      },
      "outputs": [],
      "source": [
        "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
        "    torch.save(\n",
        "        {'model_state_dict'         : model.state_dict(),\n",
        "         'optimizer_state_dict'     : optimizer.state_dict(),\n",
        "         'scheduler_state_dict'     : scheduler.state_dict(),\n",
        "         metric[0]                  : metric[1],\n",
        "         'epoch'                    : epoch},\n",
        "         path\n",
        "    )\n",
        "\n",
        "def load_model(path, model, metric= 'valid_acc', optimizer= None, scheduler= None):\n",
        "\n",
        "    checkpoint = torch.load(path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    if optimizer != None:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    if scheduler != None:\n",
        "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "\n",
        "    epoch   = checkpoint['epoch']\n",
        "    metric  = checkpoint[metric]\n",
        "\n",
        "    return [model, optimizer, scheduler, epoch, metric]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tExvyl1BIdMC"
      },
      "outputs": [],
      "source": [
        "# # This is for checkpointing, if you're doing it over multiple sessions\n",
        "\n",
        "# last_epoch_completed = 0\n",
        "# start = last_epoch_completed\n",
        "# end = config[\"epochs\"]\n",
        "best_lev_dist = float(\"inf\") # if you're restarting from some checkpoint, use what you saw there.\n",
        "epoch_model_path = f'/content/models/epoch/epoch_model_{i}.pt'#TODO set the model path( Optional, you can just store best one. Make sure to make the changes below )\n",
        "best_model_path = f'/content/models/best/best_model_{i}.pt'#TODO set best model path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JR43E28rM9Ak",
        "outputId": "82c09008-f591-4b09-8654-cfbdbd1d1c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2773\t Learning Rate 0.0011250\n",
            "\tVal Dist 5.2400%\t Val Loss 0.2704\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 2/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2606\t Learning Rate 0.0011250\n",
            "\tVal Dist 5.2811%\t Val Loss 0.2730\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 3/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2623\t Learning Rate 0.0011250\n",
            "\tVal Dist 5.2346%\t Val Loss 0.2695\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 4/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2537\t Learning Rate 0.0011250\n",
            "\tVal Dist 5.2463%\t Val Loss 0.2722\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 5/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2648\t Learning Rate 0.0011250\n",
            "\tVal Dist 5.3473%\t Val Loss 0.2706\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 6/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2515\t Learning Rate 0.0008438\n",
            "\tVal Dist 5.1172%\t Val Loss 0.2656\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 7/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2457\t Learning Rate 0.0008438\n",
            "\tVal Dist 5.1499%\t Val Loss 0.2671\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 8/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2450\t Learning Rate 0.0008438\n",
            "\tVal Dist 5.1241%\t Val Loss 0.2680\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 9/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2389\t Learning Rate 0.0006328\n",
            "\tVal Dist 5.1137%\t Val Loss 0.2748\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 10/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2247\t Learning Rate 0.0006328\n",
            "\tVal Dist 5.0124%\t Val Loss 0.2701\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 11/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2309\t Learning Rate 0.0006328\n",
            "\tVal Dist 5.0495%\t Val Loss 0.2669\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 12/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2348\t Learning Rate 0.0006328\n",
            "\tVal Dist 4.9810%\t Val Loss 0.2691\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 13/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2293\t Learning Rate 0.0006328\n",
            "\tVal Dist 5.0355%\t Val Loss 0.2632\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 14/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2172\t Learning Rate 0.0006328\n",
            "\tVal Dist 5.0620%\t Val Loss 0.2667\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 15/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2189\t Learning Rate 0.0004746\n",
            "\tVal Dist 4.9796%\t Val Loss 0.2664\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 16/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2074\t Learning Rate 0.0004746\n",
            "\tVal Dist 4.9994%\t Val Loss 0.2713\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 17/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2268\t Learning Rate 0.0004746\n",
            "\tVal Dist 5.0394%\t Val Loss 0.2689\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 18/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2175\t Learning Rate 0.0003560\n",
            "\tVal Dist 4.8674%\t Val Loss 0.2652\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 19/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2205\t Learning Rate 0.0003560\n",
            "\tVal Dist 5.0148%\t Val Loss 0.2681\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 20/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2198\t Learning Rate 0.0003560\n",
            "\tVal Dist 4.8487%\t Val Loss 0.2721\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 21/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2045\t Learning Rate 0.0003560\n",
            "\tVal Dist 4.8524%\t Val Loss 0.2694\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 22/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2112\t Learning Rate 0.0003560\n",
            "\tVal Dist 4.8494%\t Val Loss 0.2667\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 23/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2084\t Learning Rate 0.0002670\n",
            "\tVal Dist 4.8469%\t Val Loss 0.2688\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 24/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2057\t Learning Rate 0.0002670\n",
            "\tVal Dist 4.8398%\t Val Loss 0.2712\n",
            "Saved epoch model\n",
            "Saved best model\n",
            "\n",
            "Epoch: 25/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Loss 0.2044\t Learning Rate 0.0002670\n",
            "\tVal Dist 4.8779%\t Val Loss 0.2714\n",
            "Saved epoch model\n",
            "\n",
            "Epoch: 26/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train:  77%|███████▋  | 172/223 [08:04<02:34,  3.03s/it, loss=0.1993, lr=0.000267]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1769fcf35685>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mcurr_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m              \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dist\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mvalidate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphoneme_map\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mLABELS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-abb89d234fb2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# Another couple things you need for FP16.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for loss.backward()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is a replacement for optimizer.step()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This is something added just for FP16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "#TODO: Please complete the training loop\n",
        "# i=0\n",
        "for epoch in range(0, config['epochs']):\n",
        "    i += 1\n",
        "    print(\"\\nEpoch: {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr = optimizer.param_groups[0]['lr']  \n",
        "\n",
        "    train_loss              = train_model(model, train_loader, criterion, optimizer) #TODO\n",
        "    valid_loss, valid_dist  = validate_model(model, val_loader, decoder, phoneme_map= LABELS) #TODO\n",
        "    scheduler.step(valid_dist)\n",
        "\n",
        "    print(\"\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_loss, curr_lr))\n",
        "    print(\"\\tVal Dist {:.04f}%\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
        "\n",
        "\n",
        "    wandb.log({\n",
        "        'train_loss': train_loss,\n",
        "        'valid_dist': valid_dist,\n",
        "        'valid_loss': valid_loss,\n",
        "        'lr'        : curr_lr\n",
        "    })\n",
        "\n",
        "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, f'/content/models/epoch/epoch_model_{i}.pt')\n",
        "    wandb.save(f'/content/models/epoch/epoch_model_{i}.pt')\n",
        "    print(\"Saved epoch model\")\n",
        "\n",
        "    if valid_dist <= best_lev_dist:\n",
        "        best_lev_dist = valid_dist\n",
        "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, f'/content/models/best/best_model_{i}.pt')\n",
        "        wandb.save(f'/content/models/best/best_model_{i}.pt')\n",
        "        print(\"Saved best model\")\n",
        "      # You may find it interesting to exlplore Wandb Artifcats to version your models\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2H4EEj-sD32"
      },
      "source": [
        "# Generate Predictions and Submit to Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2moYJhTWsOG-",
        "outputId": "24a5cc20-25cb-40c4-fb4a-4d5879da350e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/21 [00:00<?, ?it/s]\u001b[A\n",
            "  5%|▍         | 1/21 [00:03<01:08,  3.44s/it]\u001b[A\n",
            " 10%|▉         | 2/21 [00:06<00:57,  3.02s/it]\u001b[A\n",
            " 14%|█▍        | 3/21 [00:08<00:47,  2.66s/it]\u001b[A\n",
            " 19%|█▉        | 4/21 [00:10<00:40,  2.40s/it]\u001b[A\n",
            " 24%|██▍       | 5/21 [00:13<00:41,  2.58s/it]\u001b[A\n",
            " 29%|██▊       | 6/21 [00:15<00:34,  2.31s/it]\u001b[A\n",
            " 33%|███▎      | 7/21 [00:17<00:31,  2.22s/it]\u001b[A\n",
            " 38%|███▊      | 8/21 [00:19<00:31,  2.43s/it]\u001b[A\n",
            " 43%|████▎     | 9/21 [00:22<00:30,  2.57s/it]\u001b[A\n",
            " 48%|████▊     | 10/21 [00:25<00:26,  2.43s/it]\u001b[A\n",
            " 52%|█████▏    | 11/21 [00:27<00:24,  2.47s/it]\u001b[A\n",
            " 57%|█████▋    | 12/21 [00:29<00:20,  2.32s/it]\u001b[A\n",
            " 62%|██████▏   | 13/21 [00:32<00:19,  2.41s/it]\u001b[A\n",
            " 67%|██████▋   | 14/21 [00:33<00:15,  2.14s/it]\u001b[A\n",
            " 71%|███████▏  | 15/21 [00:35<00:12,  2.07s/it]\u001b[A\n",
            " 76%|███████▌  | 16/21 [00:37<00:10,  2.12s/it]\u001b[A\n",
            " 81%|████████  | 17/21 [00:40<00:08,  2.16s/it]\u001b[A\n",
            " 86%|████████▌ | 18/21 [00:42<00:07,  2.39s/it]\u001b[A\n",
            " 90%|█████████ | 19/21 [00:45<00:04,  2.45s/it]\u001b[A\n",
            " 95%|█████████▌| 20/21 [00:47<00:02,  2.36s/it]\u001b[A\n",
            "100%|██████████| 21/21 [00:49<00:00,  2.35s/it]\n"
          ]
        }
      ],
      "source": [
        "#TODO: Make predictions\n",
        "\n",
        "# Follow the steps below:\n",
        "# 1. Create a new object for CTCBeamDecoder with larger (why?) number of beams\n",
        "# 2. Get prediction string by decoding the results of the beam decoder\n",
        "\n",
        "TEST_BEAM_WIDTH = 30 #TODO\n",
        "\n",
        "test_decoder    = CTCBeamDecoder(LABELS, beam_width = TEST_BEAM_WIDTH, log_probs_input = True) #TODO\n",
        "results = []\n",
        "\n",
        "model.eval()\n",
        "print(\"Testing\")\n",
        "for data in tqdm(test_loader):\n",
        "\n",
        "    x, lx   = data\n",
        "    x       = x.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        h, lh = model(x, lx)\n",
        "\n",
        "    prediction_string= decode_prediction(h, lh, test_decoder)# TODO call decode_prediction\n",
        "    #TODO save the output in results array.\n",
        "    results.extend(prediction_string)\n",
        "    del x, lx, h, lh\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d70dvu_lsMlv"
      },
      "outputs": [],
      "source": [
        "data_dir = f\"{root}/test-clean/random_submission.csv\"\n",
        "df = pd.read_csv(data_dir)\n",
        "df.label = results\n",
        "df.to_csv('submission.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1sZmEIs4yIz",
        "outputId": "13ab40b8-6459-4368-8052-1437bb24de33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.7 / client 1.5.8)\n",
            "100% 209k/209k [00:00<00:00, 340kB/s]\n",
            "500 - Internal Server Error\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions submit -c hw3p2asr-s24 -f submission.csv -m \"I made it!\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10 (main, Feb 16 2023, 02:49:39) [Clang 14.0.0 (clang-1400.0.29.202)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
